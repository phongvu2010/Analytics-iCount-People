import contextlib
import duckdb
import logging
import pandera.errors as pa_errors
import requests
import typer
import uvicorn

from concurrent.futures import ThreadPoolExecutor, as_completed
from duckdb import DuckDBPyConnection, Error as DuckdbError
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from sqlalchemy.exc import SQLAlchemyError
from tenacity import retry, stop_after_attempt, wait_fixed, before_sleep_log, retry_if_exception
from threading import Lock
from typing import Iterator
from typing_extensions import Annotated

from app.core.config import settings, TableConfig
from app.etl import extract, state, transform
from app.etl.load import ParquetLoader, prepare_destination, refresh_duckdb_table
from app.utils.logger import setup_logging

# C·∫•u h√¨nh logging ngay khi ·ª©ng d·ª•ng kh·ªüi ch·∫°y.
setup_logging('configs/logger.yaml')
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o Typer App ƒë·ªÉ qu·∫£n l√Ω c√°c c√¢u l·ªánh CLI.
cli_app = typer.Typer()


@contextlib.contextmanager
def _get_database_connections() -> Iterator[tuple[Engine, DuckDBPyConnection]]:
    sql_engine, duckdb_conn = None, None
    try:
        # 1. K·∫øt n·ªëi SQL Server
        logger.info("ƒêang thi·∫øt l·∫≠p k·∫øt n·ªëi t·ªõi MS SQL Server...")
        sql_engine = create_engine(settings.db.sqlalchemy_db_uri, pool_pre_ping=True)
        with sql_engine.connect() as connection:
            connection.execute(text('SELECT 1')) # Ping ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi
        logger.info("‚úÖ K·∫øt n·ªëi SQL Server th√†nh c√¥ng.")

        # 2. K·∫øt n·ªëi DuckDB
        logger.info("ƒêang thi·∫øt l·∫≠p k·∫øt n·ªëi t·ªõi DuckDB...")
        duckdb_path = str(settings.DUCKDB_PATH.resolve())
        duckdb_conn = duckdb.connect(database=duckdb_path, read_only=False)
        logger.info(f"‚úÖ K·∫øt n·ªëi DuckDB ('{duckdb_path}') th√†nh c√¥ng.\n")

        yield sql_engine, duckdb_conn

    except SQLAlchemyError as e:
        logger.critical(f"‚ùå L·ªói nghi√™m tr·ªçng khi k·∫øt n·ªëi SQL Server: {e}", exc_info=True)
        raise

    except DuckdbError as e:
        logger.critical(f"‚ùå L·ªói nghi√™m tr·ªçng khi k·∫øt n·ªëi DuckDB: {e}", exc_info=True)
        raise

    finally:
        # 3. ƒê√≥ng k·∫øt n·ªëi an to√†n
        if sql_engine:
            sql_engine.dispose()
            logger.info("K·∫øt n·ªëi SQL Server ƒë√£ ƒë∆∞·ª£c ƒë√≥ng.")

        if duckdb_conn:
            duckdb_conn.close()
            logger.info("K·∫øt n·ªëi DuckDB ƒë√£ ƒë∆∞·ª£c ƒë√≥ng.")


# --- T√çCH H·ª¢P C∆† CH·∫æ RETRY ---
# Decorator @retry s·∫Ω bao b·ªçc h√†m _process_table.
# - stop_after_attempt(3): Th·ª≠ l·∫°i t·ªëi ƒëa 3 l·∫ßn (1 l·∫ßn ƒë·∫ßu + 2 l·∫ßn th·ª≠ l·∫°i).
# - wait_fixed(15): Ch·ªù 15 gi√¢y gi·ªØa m·ªói l·∫ßn th·ª≠ l·∫°i.
# - before_sleep_log: T·ª± ƒë·ªông ghi log c·∫£nh b√°o tr∆∞·ªõc m·ªói l·∫ßn th·ª≠ l·∫°i.
# - retry_on_exception: Ch·ªâ th·ª≠ l·∫°i n·∫øu g·∫∑p c√°c l·ªói li√™n quan ƒë·∫øn DB/IO,
#   kh√¥ng th·ª≠ l·∫°i v·ªõi c√°c l·ªói logic d·ªØ li·ªáu nh∆∞ Pandera.
def is_retryable_exception(exception: BaseException) -> bool:
    return isinstance(exception, (SQLAlchemyError, DuckdbError, IOError))


@retry(
    stop=stop_after_attempt(3),
    wait=wait_fixed(15),
    before_sleep=before_sleep_log(logger, logging.WARNING),
    retry=retry_if_exception(is_retryable_exception)
)
def _process_table(
    sql_engine: Engine,
    duckdb_conn: DuckDBPyConnection,
    config: TableConfig,
    etl_state: dict,
    # ================== THAY ƒê·ªîI 2: Th√™m lock ƒë·ªÉ ƒë·∫£m b·∫£o an to√†n lu·ªìng ==================
    state_lock: Lock
    # =================================================================================
):
    logger.info(
        f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω b·∫£ng: '{config.source_table}' -> "
        f"'{config.dest_table}' (Incremental: {config.incremental})"
    )
    prepare_destination(config) # 1. Chu·∫©n b·ªã th∆∞ m·ª•c staging
    
    # ƒê·ªçc high-water mark t·ª´ state. Kh√¥ng c·∫ßn lock v√¨ ƒë√¢y l√† h√†nh ƒë·ªông ƒë·ªçc.
    last_timestamp = state.get_last_timestamp(etl_state, config.dest_table)
    data_iterator = extract.from_sql_server(sql_engine, config, last_timestamp) # 2. Extract

    total_rows, max_ts_in_run = 0, None

    # Gi·ªØ kh·ªëi try...except ƒë·ªÉ b·∫Øt l·ªói sau khi ƒë√£ retry h·∫øt s·ªë l·∫ßn
    try:
        with ParquetLoader(config) as loader:
            for chunk in data_iterator:
                # 3. Transform & Validate
                transformed_chunk = transform.run_transformations(chunk, config)
                if transformed_chunk.empty:
                    continue

                # 4. Load v√†o staging (Parquet)
                loader.write_chunk(transformed_chunk)
                total_rows += len(transformed_chunk)

                # C·∫≠p nh·∫≠t high-water mark cho l·∫ßn ch·∫°y hi·ªán t·∫°i
                current_max_ts = transform.get_max_timestamp(transformed_chunk, config)
                if current_max_ts and (max_ts_in_run is None or current_max_ts > max_ts_in_run):
                    max_ts_in_run = current_max_ts

        # 5. Load t·ª´ Parquet v√†o DuckDB
        if total_rows > 0:
            logger.info(f"ƒê√£ x·ª≠ l√Ω {total_rows} d√≤ng cho '{config.dest_table}'. B·∫Øt ƒë·∫ßu t·∫£i v√†o DuckDB.")
            refresh_duckdb_table(duckdb_conn, config, loader.has_written_data)
            logger.info(f"ƒê√£ t·∫£i th√†nh c√¥ng d·ªØ li·ªáu v√†o DuckDB '{config.dest_table}'.")

            # 6. C·∫≠p nh·∫≠t state n·∫øu l√† incremental load
            if config.incremental and max_ts_in_run:
                # ================== THAY ƒê·ªîI 3: S·ª≠ d·ª•ng lock khi c·∫≠p nh·∫≠t state ==================
                with state_lock:
                    state.update_timestamp(etl_state, config.dest_table, max_ts_in_run)
                    state.save_etl_state(etl_state) # L∆∞u state ngay sau khi x·ª≠ l√Ω th√†nh c√¥ng
                # ===============================================================================
        else:
            logger.info(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu m·ªõi cho '{config.dest_table}'.")
        
        # Tr·∫£ v·ªÅ t√™n b·∫£ng n·∫øu th√†nh c√¥ng
        return config.source_table

    # B·∫Øt c√°c l·ªói kh√¥ng th·ªÉ retry (v√≠ d·ª•: l·ªói validation) ho·∫∑c l·ªói sau khi ƒë√£ retry h·∫øt
    except pa_errors.SchemaErrors as e:
        logger.error(f"‚ùå L·ªói validation d·ªØ li·ªáu kh√¥ng th·ªÉ retry cho '{config.source_table}': {e}", exc_info=True)
        raise # N√©m l·∫°i l·ªói ƒë·ªÉ v√≤ng l·∫∑p ch√≠nh b·∫Øt ƒë∆∞·ª£c

    except Exception as e:
        logger.error(f"‚ùå ƒê√£ x·∫£y ra l·ªói kh√¥ng th·ªÉ ph·ª•c h·ªìi sau c√°c l·∫ßn th·ª≠ l·∫°i cho '{config.source_table}': {e}", exc_info=True)
        raise


def _trigger_cache_clear(host: str, port: int):
    # Ch·ªâ th·ª±c hi·ªán n·∫øu API token ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh
    if not settings.INTERNAL_API_TOKEN:
        logger.warning("INTERNAL_API_TOKEN ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh, b·ªè qua vi·ªác x√≥a cache.")
        return

    clear_cache_url = f"http://{host}:{port}/api/v1/admin/clear-cache"
    headers = {"X-Internal-Token": settings.INTERNAL_API_TOKEN}

    try:
        logger.info(f"ƒêang g·ª≠i y√™u c·∫ßu x√≥a cache ƒë·∫øn {clear_cache_url}...")
        response = requests.post(clear_cache_url, headers=headers, timeout=10)
        response.raise_for_status() # N√©m l·ªói n·∫øu status code l√† 4xx ho·∫∑c 5xx
        if response.status_code == 204:
            logger.info("‚úÖ Y√™u c·∫ßu x√≥a cache ƒë∆∞·ª£c API server ch·∫•p nh·∫≠n th√†nh c√¥ng.")
    except requests.exceptions.RequestException as e:
        logger.error(f"‚ùå Kh√¥ng th·ªÉ x√≥a cache c·ªßa API server: {e}")
        logger.warning("L∆∞u √Ω: D·ªØ li·ªáu m·ªõi c√≥ th·ªÉ m·∫•t t·ªõi 30 ph√∫t ƒë·ªÉ hi·ªÉn th·ªã tr√™n dashboard.")


@cli_app.command()
def run_etl(
    # Th√™m t√πy ch·ªçn ƒë·ªÉ gi·ªõi h·∫°n s·ªë lu·ªìng, m·∫∑c ƒë·ªãnh l√† 4
    max_workers: int = typer.Option(4, help="S·ªë lu·ªìng t·ªëi ƒëa ƒë·ªÉ x·ª≠ l√Ω ETL song song."),
    # Th√™m t√πy ch·ªçn ƒë·ªÉ k√≠ch ho·∫°t/v√¥ hi·ªáu h√≥a vi·ªác x√≥a cache
    clear_cache: bool = typer.Option(True, help="T·ª± ƒë·ªông x√≥a cache c·ªßa API server sau khi ETL xong."),
    api_host: str = typer.Option("127.0.0.1", help="Host c·ªßa API server ƒëang ch·∫°y."),
    api_port: int = typer.Option(8000, help="Port c·ªßa API server ƒëang ch·∫°y."),
):
    logger.info("=" * 60)
    logger.info(f"üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH ETL (t·ªëi ƒëa {max_workers} lu·ªìng)")
    logger.info("=" * 60)

    succeeded, failed = [], []
    etl_state = state.load_etl_state()

    # ================== THAY ƒê·ªîI 4: Kh·ªüi t·∫°o Lock v√† ThreadPoolExecutor ==================
    state_lock = Lock()
    
    # S·∫Øp x·∫øp c√°c b·∫£ng theo th·ª© t·ª± x·ª≠ l√Ω ƒë√£ ƒë·ªãnh nghƒ©a trong config.
    # ƒêi·ªÅu n√†y v·∫´n quan tr·ªçng n·∫øu c√≥ c√°c b·∫£ng ph·ª• thu·ªôc (v√≠ d·ª•: dim table ph·∫£i ch·∫°y tr∆∞·ªõc fact table)
    # ThreadPoolExecutor s·∫Ω t√¥n tr·ªçng th·ª© t·ª± submit task.
    tables_to_process = sorted(
        settings.TABLE_CONFIG.values(),
        key=lambda config: config.processing_order
    )

    try:
        with _get_database_connections() as (sql_engine, duckdb_conn):
            # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ ch·∫°y c√°c t√°c v·ª• song song
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # T·∫°o m·ªôt future cho m·ªói b·∫£ng c·∫ßn x·ª≠ l√Ω
                future_to_table = {
                    executor.submit(_process_table, sql_engine, duckdb_conn, config, etl_state, state_lock): config
                    for config in tables_to_process
                }

                # L·∫∑p qua c√°c future khi ch√∫ng ho√†n th√†nh
                for future in as_completed(future_to_table):
                    config = future_to_table[future]
                    try:
                        # L·∫•y k·∫øt qu·∫£ (t√™n b·∫£ng) n·∫øu th√†nh c√¥ng
                        result = future.result()
                        succeeded.append(result)
                        logger.info(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng '{config.source_table}'.\n")
                    except Exception:
                        # Exception ·ªü ƒë√¢y nghƒ©a l√† h√†m ƒë√£ retry h·∫øt s·ªë l·∫ßn m√† v·∫´n l·ªói
                        failed.append(config.source_table)
                        logger.error(
                            f"‚ùå X·ª≠ l√Ω '{config.source_table}' th·∫•t b·∫°i sau t·∫•t c·∫£ c√°c l·∫ßn th·ª≠ l·∫°i. "
                            f"Chi ti·∫øt l·ªói ƒë√£ ƒë∆∞·ª£c log ·ªü tr√™n.\n"
                        )
    # =====================================================================================

    except Exception as e:
        logger.critical(f"Quy tr√¨nh ETL b·ªã d·ª´ng do l·ªói k·∫øt n·ªëi ban ƒë·∫ßu: {e}")

    finally:
        # ================== THAY ƒê·ªîI 3: K√≠ch ho·∫°t x√≥a cache sau khi ETL k·∫øt th√∫c ==================
        # Ch·ªâ x√≥a cache n·∫øu ETL ch·∫°y th√†nh c√¥ng √≠t nh·∫•t 1 b·∫£ng v√† ng∆∞·ªùi d√πng cho ph√©p
        if clear_cache and succeeded:
             _trigger_cache_clear(host=api_host, port=api_port)
        # ======================================================================================

        logger.info("=" * 60)
        logger.info("üìä T√ìM T·∫ÆT K·∫æT QU·∫¢ ETL")
        logger.info(f"T·ªïng s·ªë b·∫£ng: {len(tables_to_process)}")
        logger.info(f"‚úÖ Th√†nh c√¥ng: {len(succeeded)}")
        logger.info(f"‚ùå Th·∫•t b·∫°i: {len(failed)}")
        if failed:
            logger.warning(f"Danh s√°ch b·∫£ng th·∫•t b·∫°i: {', '.join(failed)}")
        logger.info("=" * 60 + "\n")


@cli_app.command()
def init_db():
    """
    Kh·ªüi t·∫°o ho·∫∑c c·∫≠p nh·∫≠t c√°c ƒë·ªëi t∆∞·ª£ng database c·∫ßn thi·∫øt, nh∆∞ VIEWs.

    L·ªánh n√†y n√™n ƒë∆∞·ª£c ch·∫°y m·ªôt l·∫ßn khi thi·∫øt l·∫≠p d·ª± √°n, ho·∫∑c m·ªói khi c√≥
    thay ƒë·ªïi v·ªÅ logic nghi·ªáp v·ª• trong VIEW (v√≠ d·ª•: thay ƒë·ªïi ng∆∞·ª°ng outlier).
    """
    logger.info("B·∫Øt ƒë·∫ßu kh·ªüi t·∫°o/c·∫≠p nh·∫≠t c√°c VIEWs trong DuckDB...")

    # Logic x·ª≠ l√Ω outlier ƒë∆∞·ª£c l·∫•y t·ª´ config ƒë·ªÉ VIEW lu√¥n ƒë·ªìng b·ªô v·ªõi c√†i ƒë·∫∑t.
    scale = settings.OUTLIER_SCALE_RATIO
    then_logic_in = f'CAST(ROUND(a.visitors_in * {scale}, 0) AS INTEGER)' if scale > 0 else '1'
    then_logic_out = f'CAST(ROUND(a.visitors_out * {scale}, 0) AS INTEGER)' if scale > 0 else '1'
    
    # VIEW n√†y s·∫Ω chu·∫©n h√≥a d·ªØ li·ªáu, x·ª≠ l√Ω outlier v√† ƒëi·ªÅu ch·ªânh "ng√†y l√†m vi·ªác".
    # ƒê√¢y ch√≠nh l√† logic t·ª´ h√†m `_build_base_query` c≈© trong services.py.
    create_view_sql = f"""
    CREATE OR REPLACE VIEW v_traffic_normalized AS
    SELECT
        CAST(a.recorded_at AS TIMESTAMP) as record_time,
        b.store_name,
        CASE
            WHEN a.visitors_in > {settings.OUTLIER_THRESHOLD} THEN {then_logic_in}
            ELSE a.visitors_in
        END as in_count,
        CASE
            WHEN a.visitors_out > {settings.OUTLIER_THRESHOLD} THEN {then_logic_out}
            ELSE a.visitors_out
        END as out_count,
        -- D·ªãch chuy·ªÉn th·ªùi gian ƒë·ªÉ ng√†y l√†m vi·ªác b·∫Øt ƒë·∫ßu t·ª´ 00:00
        (CAST(a.recorded_at AS TIMESTAMP) - INTERVAL '{settings.WORKING_HOUR_START} hours') AS adjusted_time
    FROM fact_traffic AS a
    LEFT JOIN dim_stores AS b ON a.store_id = b.store_id;
    """
    
    try:
        # K·∫øt n·ªëi tr·ª±c ti·∫øp ƒë·∫øn file DuckDB ƒë·ªÉ th·ª±c thi l·ªánh
        db_path = str(settings.DUCKDB_PATH.resolve())
        with duckdb.connect(database=db_path, read_only=False) as conn:
            conn.execute(create_view_sql)
        logger.info("‚úÖ ƒê√£ t·∫°o/c·∫≠p nh·∫≠t th√†nh c√¥ng VIEW 'v_traffic_normalized'.")
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi kh·ªüi t·∫°o VIEW: {e}", exc_info=True)
        raise typer.Exit(code=1)


@cli_app.command()
def serve(
    host: Annotated[str, typer.Option(help="Host ƒë·ªÉ ch·∫°y server.")] = '127.0.0.1',
    port: Annotated[int, typer.Option(help="Port ƒë·ªÉ ch·∫°y server.")] = 8000,
    reload: Annotated[bool, typer.Option(help="T·ª± ƒë·ªông t·∫£i l·∫°i khi code thay ƒë·ªïi.")] = True,
):
    logger.info(f"üöÄ Kh·ªüi ch·∫°y FastAPI server t·∫°i http://{host}:{port}")
    uvicorn.run(
        'app.main:api_app',
        host=host,
        port=port,
        reload=reload,
        reload_dirs=['app', 'configs', 'template'] # Ch·ªâ ƒë·ªãnh r√µ th∆∞ m·ª•c c·∫ßn theo d√µi
    )


if __name__ == '__main__':
    cli_app()
