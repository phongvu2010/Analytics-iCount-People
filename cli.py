"""
Giao di·ªán d√≤ng l·ªánh (CLI) ch√≠nh c·ªßa ·ª©ng d·ª•ng.

File n√†y s·ª≠ d·ª•ng Typer ƒë·ªÉ t·∫°o ra c√°c l·ªánh gi√∫p t∆∞∆°ng t√°c v·ªõi ·ª©ng d·ª•ng,
bao g·ªìm vi·ªác ch·∫°y quy tr√¨nh ETL v√† kh·ªüi ch·∫°y m√°y ch·ªß web.
ƒê√¢y l√† ƒëi·ªÉm kh·ªüi ƒë·∫ßu (entrypoint) cho c√°c t√°c v·ª• v·∫≠n h√†nh.
"""
import contextlib
import duckdb
import logging
import typer
import uvicorn

from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from sqlalchemy.exc import SQLAlchemyError
from typing import Iterator
from typing_extensions import Annotated

from app.main import api_app
from app.core.config import settings, TableConfig
from app.etl import state, extract, transform
from app.etl.load import ParquetLoader, prepare_destination, refresh_duckdb_table
from app.utils.logger import setup_logging

# C·∫•u h√¨nh logging ngay khi ·ª©ng d·ª•ng kh·ªüi ch·∫°y
setup_logging('configs/logger.yaml')
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o Typer App
cli_app = typer.Typer()

@contextlib.contextmanager
def _get_database_connections() -> Iterator[tuple[Engine, duckdb.DuckDBPyConnection]]:
    """
    Context manager ƒë·ªÉ qu·∫£n l√Ω v√≤ng ƒë·ªùi c·ªßa c√°c k·∫øt n·ªëi database.

    T·ª± ƒë·ªông thi·∫øt l·∫≠p k·∫øt n·ªëi ƒë·∫øn MS SQL Server v√† DuckDB khi b·∫Øt ƒë·∫ßu
    v√† ƒë·∫£m b·∫£o ch√∫ng ƒë∆∞·ª£c ƒë√≥ng l·∫°i m·ªôt c√°ch an to√†n khi k·∫øt th√∫c,
    ngay c·∫£ khi c√≥ l·ªói x·∫£y ra.

    Yields:
        Iterator[tuple[Engine, duckdb.DuckDBPyConnection]]: M·ªôt tuple ch·ª©a
        SQLAlchemy engine v√† k·∫øt n·ªëi DuckDB.

    Raises:
        SQLAlchemyError: N·∫øu kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn SQL Server.
        duckdb.Error: N·∫øu kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn DuckDB.
    """
    sql_engine, duckdb_conn = None, None
    try:
        # 1. K·∫øt n·ªëi SQL Server
        logger.info('ƒêang thi·∫øt l·∫≠p k·∫øt n·ªëi t·ªõi MS SQL Server...')
        sql_engine = create_engine(settings.db.sqlalchemy_db_uri, pool_pre_ping=True)
        with sql_engine.connect() as connection:
            connection.execute(text('SELECT 1')) # Ping ƒë·ªÉ ki·ªÉm tra k·∫øt n·ªëi
        logger.info('‚úÖ K·∫øt n·ªëi SQL Server th√†nh c√¥ng.')

        # 2. K·∫øt n·ªëi DuckDB
        logger.info('ƒêang thi·∫øt l·∫≠p k·∫øt n·ªëi t·ªõi DuckDB...')
        duckdb_path = str(settings.DUCKDB_PATH.resolve())
        duckdb_conn = duckdb.connect(database=duckdb_path, read_only=False)
        logger.info(f"‚úÖ K·∫øt n·ªëi DuckDB ('{duckdb_path}') th√†nh c√¥ng.\n")

        yield sql_engine, duckdb_conn
    except SQLAlchemyError as e:
        logger.critical(f"‚ùå L·ªói nghi√™m tr·ªçng khi k·∫øt n·ªëi SQL Server: {e}\n", exc_info=True)
        raise
    except duckdb.Error as e:
        logger.critical(f"‚ùå L·ªói nghi√™m tr·ªçng khi k·∫øt n·ªëi DuckDB: {e}\n", exc_info=True)
        raise
    finally:
        # 3. ƒê√≥ng k·∫øt n·ªëi
        if sql_engine:
            sql_engine.dispose()
            logger.info('K·∫øt n·ªëi SQL Server ƒë√£ ƒë∆∞·ª£c ƒë√≥ng.')

        if duckdb_conn:
            duckdb_conn.close()
            logger.info('K·∫øt n·ªëi DuckDB ƒë√£ ƒë∆∞·ª£c ƒë√≥ng.')

def _process_table(sql_engine: Engine, duckdb_conn: duckdb.DuckDBPyConnection, config: TableConfig, etl_state: dict):
    """
    Th·ª±c hi·ªán to√†n b·ªô pipeline ETL cho m·ªôt b·∫£ng duy nh·∫•t.
    Bao g·ªìm Extract, Transform, v√† Load.

    Args:
        sql_engine (Engine): SQLAlchemy engine ƒë√£ k·∫øt n·ªëi.
        duckdb_conn (duckdb.DuckDBPyConnection): K·∫øt n·ªëi DuckDB ƒëang ho·∫°t ƒë·ªông.
        config (TableConfig): ƒê·ªëi t∆∞·ª£ng c·∫•u h√¨nh cho b·∫£ng ƒëang x·ª≠ l√Ω.
        etl_state (dict): Dictionary ch·ª©a tr·∫°ng th√°i (high-water mark) c·ªßa ETL.
    """
    logger.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω b·∫£ng: '{config.source_table}' -> '{config.dest_table}' (Incremental: {config.incremental})")

    # 1. Chu·∫©n b·ªã th∆∞ m·ª•c ƒë√≠ch (staging area)
    prepare_destination(config)

    # 2. L·∫•y high-water mark t·ª´ l·∫ßn ch·∫°y th√†nh c√¥ng cu·ªëi c√πng
    last_timestamp = state.get_last_timestamp(etl_state, config.dest_table)

    # 3. Tr√≠ch xu·∫•t d·ªØ li·ªáu (Extract)
    data_iterator = extract.from_sql_server(sql_engine, config, last_timestamp)

    total_rows, max_ts_in_run = 0, None
    try:
        # S·ª≠ d·ª•ng ParquetLoader ƒë·ªÉ ghi d·ªØ li·ªáu theo t·ª´ng kh·ªëi (chunk)
        with ParquetLoader(config) as loader:
            for chunk in data_iterator:
                if chunk.empty: continue

                # 4. Bi·∫øn ƒë·ªïi d·ªØ li·ªáu (Transform)
                transformed_chunk = transform.run_transformations(chunk, config)
                if transformed_chunk.empty: continue

                # 5. T·∫£i d·ªØ li·ªáu v√†o staging area (d∆∞·ªõi d·∫°ng file Parquet)
                loader.write_chunk(transformed_chunk)
                total_rows += len(transformed_chunk)

                # 6. C·∫≠p nh·∫≠t high-water mark cho l·∫ßn ch·∫°y hi·ªán t·∫°i
                current_max_ts = transform.get_max_timestamp(transformed_chunk, config)
                if current_max_ts and (max_ts_in_run is None or current_max_ts > max_ts_in_run):
                    max_ts_in_run = current_max_ts

        # 7. T·∫£i d·ªØ li·ªáu t·ª´ Parquet v√†o DuckDB (Load)
        if total_rows > 0:
            logger.info(f"ƒê√£ x·ª≠ l√Ω {total_rows} d√≤ng. B·∫Øt ƒë·∫ßu t·∫£i v√†o DuckDB.")
            refresh_duckdb_table(duckdb_conn, config, loader.has_written_data)
            logger.info(f"ƒê√£ t·∫£i th√†nh c√¥ng d·ªØ li·ªáu v√†o b·∫£ng DuckDB '{config.dest_table}'.")

            # 8. C·∫≠p nh·∫≠t state n·∫øu l√† incremental load
            if config.incremental and max_ts_in_run:
                state.update_timestamp(etl_state, config.dest_table, max_ts_in_run)
        else:
            logger.info(f"Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu m·ªõi cho b·∫£ng '{config.dest_table}'.")
    except Exception as e:
        logger.error(f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω cho b·∫£ng '{config.dest_table}': {e}", exc_info=True)
        raise # N√©m l·∫°i l·ªói ƒë·ªÉ v√≤ng l·∫∑p ch√≠nh b·∫Øt v√† ƒë√°nh d·∫•u l√† FAILED

@cli_app.command()
def run_etl():
    """ Ch·∫°y quy tr√¨nh ETL ho√†n ch·ªânh t·ª´ SQL Server sang DuckDB. """
    logger.info('='*60)
    logger.info('üöÄ B·∫ÆT ƒê·∫¶U QUY TR√åNH ETL')
    logger.info('='*60)

    succeeded_tables, failed_tables = [], []
    etl_state = state.load_etl_state()

    # S·∫Øp x·∫øp c√°c b·∫£ng theo th·ª© t·ª± x·ª≠ l√Ω ƒë√£ ƒë·ªãnh nghƒ©a trong config.
    # ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o c√°c b·∫£ng dimension ƒë∆∞·ª£c t·∫°o/c·∫≠p nh·∫≠t tr∆∞·ªõc c√°c b·∫£ng fact.
    tables_to_process = sorted(
        settings.TABLE_CONFIG.items(),
        key=lambda item: item[1].processing_order
    )

    try:
        # S·ª≠ d·ª•ng context manager ƒë·ªÉ qu·∫£n l√Ω k·∫øt n·ªëi m·ªôt c√°ch an to√†n
        with _get_database_connections() as (sql_engine, duckdb_conn):
            # L·∫∑p qua danh s√°ch c√°c b·∫£ng ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp
            for table_name, config in tables_to_process:
                try:
                    _process_table(sql_engine, duckdb_conn, config, etl_state)
                    # L∆∞u l·∫°i tr·∫°ng th√°i ngay sau khi m·ªôt b·∫£ng x·ª≠ l√Ω th√†nh c√¥ng
                    state.save_etl_state(etl_state)
                    succeeded_tables.append(config.source_table)
                    logger.info(f"‚úÖ X·ª≠ l√Ω th√†nh c√¥ng b·∫£ng '{config.source_table}'.\n")
                except Exception:
                    # N·∫øu c√≥ l·ªói, ghi nh·∫≠n v√† ti·∫øp t·ª•c v·ªõi b·∫£ng ti·∫øp theo
                    failed_tables.append(config.source_table)
                    logger.error(f"‚ùå X·ª≠ l√Ω b·∫£ng '{config.source_table}' th·∫•t b·∫°i. Chuy·ªÉn sang b·∫£ng ti·∫øp theo.\n")
                    continue
    except Exception as e:
        logger.critical(f"Quy tr√¨nh ETL b·ªã d·ª´ng do l·ªói k·∫øt n·ªëi ho·∫∑c l·ªói nghi√™m tr·ªçng kh√°c: {e}")
    finally:
        # In ra b·∫£n t√≥m t·∫Øt k·∫øt qu·∫£ cu·ªëi c√πng
        logger.info('='*60)
        logger.info('üìä T√ìM T·∫ÆT K·∫æT QU·∫¢ ETL')
        logger.info(f"T·ªïng s·ªë b·∫£ng c·∫•u h√¨nh: {len(settings.TABLE_CONFIG)}")
        logger.info(f"‚úÖ Th√†nh c√¥ng: {len(succeeded_tables)}")
        logger.info(f"‚ùå Th·∫•t b·∫°i: {len(failed_tables)}")
        if failed_tables:
            logger.warning(f"Danh s√°ch b·∫£ng th·∫•t b·∫°i: {', '.join(failed_tables)}")
        logger.info('='*60 + '\n')

@cli_app.command()
def serve(
    host: Annotated[str, typer.Option(help='Host ƒë·ªÉ ch·∫°y server.')] = '127.0.0.1',
    port: Annotated[int, typer.Option(help='Port ƒë·ªÉ ch·∫°y server.')] = 8000,
    reload: Annotated[bool, typer.Option(help='T·ª± ƒë·ªông t·∫£i l·∫°i server khi c√≥ thay ƒë·ªïi.')] = True
):
    """ Kh·ªüi ch·∫°y web server Uvicorn cho ·ª©ng d·ª•ng FastAPI. """
    # Ch·ªâ ƒë·ªãnh r√µ th∆∞ m·ª•c c·∫ßn gi√°m s√°t cho vi·ªác t·ª± ƒë·ªông t·∫£i l·∫°i
    reload_dirs = ['app', 'configs', 'template']

    logger.info(f"üöÄ Kh·ªüi ch·∫°y FastAPI server t·∫°i http://{host}:{port}")
    uvicorn.run(
        'app.main:api_app',
        host=host,
        port=port,
        reload=reload,
        reload_dirs=reload_dirs  # Tham s·ªë n√†y ƒë·ªÉ ch·ªâ ƒë·ªãnh th∆∞ m·ª•c c·∫ßn theo d√µi
    )

if __name__ == '__main__':
    cli_app()
